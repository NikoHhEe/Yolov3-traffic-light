{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yolo v3 model import\n",
    "Run this block to import necessary libraries used by the code, and also the yolo v3 model.  \n",
    "Two models can be selected, yolov3.weights and yolov3-tiny.weights, which have different performance.  \n",
    "Select one of them by commenting the other line out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load Yolo\n",
    "net = cv2.dnn.readNet(\"weights/yolov3-tiny.weights\", \"cfg/yolov3-tiny.cfg\")\n",
    "# net = cv2.dnn.readNet(\"weights/yolov3.weights\", \"cfg/yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"data/coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color detection implementation\n",
    "This is the implementation of color detection.  \n",
    "Input is an RGB image containing a traffic light.  \n",
    "Output is a string indicating the color name of the traffic light in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color detection\n",
    "def detect_color(image):\n",
    "    # Convert the imageFrame in \n",
    "    # BGR(RGB color space) to \n",
    "    # HSV(hue-saturation-value)\n",
    "    # color space\n",
    "    hsvFrame = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "  \n",
    "    # Set range for red color and \n",
    "    # define mask\n",
    "    red_lower = np.array([136, 87, 111], np.uint8)\n",
    "    red_upper = np.array([180, 255, 255], np.uint8)\n",
    "    red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "  \n",
    "    # Set range for green color and \n",
    "    # define mask\n",
    "    green_lower = np.array([25, 52, 72], np.uint8)\n",
    "    green_upper = np.array([102, 255, 255], np.uint8)\n",
    "    green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "\n",
    "    # Set range for yellow color and \n",
    "    # define mask\n",
    "    yellow_lower = np.array([22, 93, 0], np.uint8)\n",
    "    yellow_upper = np.array([45, 255, 255], np.uint8)\n",
    "    yellow_mask = cv2.inRange(hsvFrame, yellow_lower, yellow_upper)\n",
    "  \n",
    "    # Morphological Transform, Dilation\n",
    "    # for each color and bitwise_and operator\n",
    "    # between imageFrame and mask determines\n",
    "    # to detect only that particular color\n",
    "    kernal = np.ones((5, 5), \"uint8\")\n",
    "      \n",
    "    # For red color\n",
    "    red_mask = cv2.dilate(red_mask, kernal)\n",
    "      \n",
    "    # For green color\n",
    "    green_mask = cv2.dilate(green_mask, kernal)\n",
    "    \n",
    "    # For yellow color\n",
    "    yellow_mask = cv2.dilate(yellow_mask, kernal)\n",
    "\n",
    "     # Creating contour to track red color\n",
    "    contours, hierarchy = cv2.findContours(red_mask,\n",
    "                                           cv2.RETR_TREE,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "      \n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "            return 'Red'\n",
    "  \n",
    "    # Creating contour to track green color\n",
    "    contours, hierarchy = cv2.findContours(green_mask,\n",
    "                                           cv2.RETR_TREE,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "      \n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "            return 'Green'\n",
    "\n",
    "    # Creating contour to track yellow color\n",
    "    contours, hierarchy = cv2.findContours(yellow_mask,\n",
    "                                           cv2.RETR_TREE,\n",
    "                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "            return 'Yellow'\n",
    "    \n",
    "    return 'None'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function\n",
    "The main function starts here. A video is loaded first, different videos can be tested by changeing the file name in cv2.VideoCapture().\n",
    "The information of video is retrieved and each frame is detected with yolo first and the traffic light region is preocessed with the color detection function. Then the light color of each frame can be obtained and displayed in real time. After the last frame is processed, the output image of each frame are put together into a complete video which is stored locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('test1.mp4')\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# get the properties of the input video\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "# Define the codec and create VideoWriter object to store video\n",
    "output = cv2.VideoWriter('output.mp4',fourcc, fps, size)\n",
    "\n",
    "starting_time = time.time()\n",
    "frame_id = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame_id += 1\n",
    "        height, width, channels = frame.shape\n",
    "\n",
    "        # Detecting objects\n",
    "        mean=(0, 0, 0)\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), mean, swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(output_layers)\n",
    "\n",
    "        # plotting the objects detected\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        light_colors = []\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                # check only traffic light class (class 9)\n",
    "                if (class_id != 9):\n",
    "                    continue\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.3:\n",
    "                    # when confidence over threshold object detected\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    # Rectangle coordinates\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "                    if (x >= 0 and y >= 0):\n",
    "                        # get the target region with traffic lights\n",
    "                        target_img = frame[y:y+h,x:x+w]\n",
    "\n",
    "                    # detect color in the region\n",
    "                    if not (target_img is None):\n",
    "                        light_color = detect_color(target_img)\n",
    "    \n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "                    light_colors.append(light_color)\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.3)\n",
    "\n",
    "        # display boxes and texts of each traffic light detected\n",
    "        for i in range(len(boxes)):\n",
    "            if i in indexes:\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(classes[class_ids[i]])\n",
    "                confidence = confidences[i]\n",
    "                light_color = light_colors[i]\n",
    "                color = (0, 0, 0)\n",
    "                if (light_color == 'Red'):\n",
    "                    color = (0, 0, 255)\n",
    "                if (light_color == 'Yellow'):\n",
    "                    color = (0, 255, 255)\n",
    "                if (light_color == 'Green'):\n",
    "                    color = (0, 255, 0)\n",
    "                \n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                cv2.putText(frame, light_color + str(round(confidence, 2)), (x+w+10, y+30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "        elapsed_time = time.time() - starting_time\n",
    "        fps = frame_id / elapsed_time\n",
    "        cv2.putText(frame, \"FPS: \" + str(round(fps, 2)), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3)\n",
    "        cv2.imshow(\"Image\", frame)\n",
    "        output.write(frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "# close the videowriter\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc5f70855ac006f3de45a3cc3b9e7d8d53845e50458809cb162b0174266dec97"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
